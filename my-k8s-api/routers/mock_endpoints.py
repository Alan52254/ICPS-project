# Mock endpoints for testing frontend functionality
from fastapi import APIRouter
from pydantic import BaseModel
from typing import List, Optional

router = APIRouter()

# Mock data
mock_namespaces = ["default", "kube-system", "monitoring", "prod", "staging"]

mock_pod_metrics = {
    "default": [
        {"pod": "nginx-deployment-7d7c6d8b9f-abc12", "cpu": 0.0234, "mem": 128.5, "disk": 1024.2, "net_rx": 15.3, "net_tx": 8.7, "ready": True},
        {"pod": "redis-master-6b8c7d9e8f-def34", "cpu": 0.0156, "mem": 256.8, "disk": 512.1, "net_rx": 23.1, "net_tx": 12.4, "ready": True},
        {"pod": "postgres-db-5a7b8c9d0e-ghi56", "cpu": 0.0445, "mem": 512.3, "disk": 2048.7, "net_rx": 31.2, "net_tx": 18.9, "ready": False},
    ],
    "kube-system": [
        {"pod": "kube-dns-7f4c8d9e8f-xyz01", "cpu": 0.0089, "mem": 64.2, "disk": 256.1, "net_rx": 12.5, "net_tx": 6.3, "ready": True},
        {"pod": "kube-proxy-4f6g7h8i9j-abc02", "cpu": 0.0067, "mem": 48.7, "disk": 128.5, "net_rx": 8.2, "net_tx": 4.1, "ready": True},
    ],
    "monitoring": [
        {"pod": "prometheus-server-3e5f6g7h8i-mon01", "cpu": 0.1234, "mem": 1024.8, "disk": 4096.2, "net_rx": 145.7, "net_tx": 89.3, "ready": True},
        {"pod": "grafana-dashboard-2d4f5g6h7i-gra01", "cpu": 0.0456, "mem": 384.5, "disk": 1536.8, "net_rx": 67.2, "net_tx": 34.6, "ready": True},
        {"pod": "alertmanager-1c3e5f7g9h-alt01", "cpu": 0.0089, "mem": 128.3, "disk": 512.4, "net_rx": 23.8, "net_tx": 12.7, "ready": False},
    ],
    "prod": [
        {"pod": "api-service-4f6g7h8i9j-jkl78", "cpu": 0.0789, "mem": 384.6, "disk": 1536.4, "net_rx": 42.8, "net_tx": 26.1, "ready": True},
        {"pod": "worker-queue-3e5f6g7h8i-mno90", "cpu": 0.0123, "mem": 192.1, "disk": 768.9, "net_rx": 8.5, "net_tx": 4.2, "ready": True},
        {"pod": "database-primary-2d4e6f8g0h-db001", "cpu": 0.1567, "mem": 2048.7, "disk": 8192.3, "net_rx": 234.5, "net_tx": 156.8, "ready": True},
    ],
    "staging": [
        {"pod": "test-app-1a2b3c4d5e-test01", "cpu": 0.0234, "mem": 256.4, "disk": 1024.1, "net_rx": 34.7, "net_tx": 18.9, "ready": True},
    ]
}

class ChatRequest(BaseModel):
    user_message: str
    history: Optional[List[dict]] = None

class ChatResponse(BaseModel):
    assistant: str
    history: List[dict]

@router.get("/namespaces")
async def get_namespaces():
    """Get list of available namespaces"""
    return {"namespaces": mock_namespaces}

@router.get("/pod_metrics")
async def get_pod_metrics(namespace: str = "default"):
    """Get pod metrics for a specific namespace"""
    return mock_pod_metrics.get(namespace, [])

@router.post("/llm_chat", response_model=ChatResponse)
async def llm_chat(req: ChatRequest):
    """Mock LLM chat endpoint"""
    user_message = req.user_message
    current_history = req.history or []
    
    # Simple mock response based on user message
    if "pod" in user_message.lower() or "è³‡æº" in user_message or "metrics" in user_message.lower():
        assistant_response = f"""æ ¹æ“šæ‚¨çš„æŸ¥è©¢ã€Œ{user_message}ã€ï¼Œæˆ‘ç‚ºæ‚¨åˆ†æç•¶å‰é›†ç¾¤ç‹€æ³ï¼š

**ğŸ” é›†ç¾¤è³‡æºæ¦‚æ³ï¼š**
- ç¸½å…± {len(mock_namespaces)} å€‹å‘½åç©ºé–“æ­£åœ¨é‹è¡Œ
- ç™¼ç¾é«˜è³‡æºä½¿ç”¨çš„ Podï¼š`database-primary-2d4e6f8g0h-db001` (CPU: 0.1567 cores)
- æœ‰ 1 å€‹ Pod è™•æ–¼æœªå°±ç·’ç‹€æ…‹éœ€è¦é—œæ³¨

**ğŸ’¡ å»ºè­°ï¼š**
1. æª¢æŸ¥æœªå°±ç·’çš„ Pod æ—¥èªŒ
2. è€ƒæ…®èª¿æ•´è³‡æºé™åˆ¶
3. ç›£æ§ç£ç¢Ÿä½¿ç”¨æƒ…æ³

é€™æ˜¯æ¼”ç¤ºæ¨¡å¼çš„å›æ‡‰ã€‚åœ¨å¯¦éš›ç’°å¢ƒä¸­ï¼Œæˆ‘æœƒæŸ¥è©¢çœŸå¯¦çš„ Prometheus æŒ‡æ¨™æ•¸æ“šã€‚"""
    
    elif "help" in user_message.lower() or "å¹«åŠ©" in user_message or "åŠŸèƒ½" in user_message:
        assistant_response = """**ğŸ¤– AI åŠ©æ‰‹åŠŸèƒ½ä»‹ç´¹ï¼š**

æˆ‘å¯ä»¥å”åŠ©æ‚¨ï¼š

**ğŸ“Š ç›£æ§åˆ†æï¼š**
- æŸ¥è©¢ Pod è³‡æºä½¿ç”¨æƒ…æ³
- åˆ†æ CPUã€è¨˜æ†¶é«”ã€ç¶²è·¯æŒ‡æ¨™
- è­˜åˆ¥æ•ˆèƒ½ç“¶é ¸

**ğŸ”§ æ•…éšœæ’é™¤ï¼š**
- è¨ºæ–· Pod ç‹€æ…‹ç•°å¸¸
- æä¾›æœ€ä½³åŒ–å»ºè­°
- å®¹é‡è¦åŠƒæŒ‡å°

**ğŸ’¬ ä½¿ç”¨æ–¹å¼ï¼š**
- ç›´æ¥è©¢å•é›†ç¾¤ç›¸é—œå•é¡Œ
- æ”¯æ´ä¸­è‹±æ–‡æŸ¥è©¢
- å¯æŸ¥çœ‹å³æ™‚æŒ‡æ¨™æ•¸æ“š

ç›®å‰ç‚ºæ¼”ç¤ºæ¨¡å¼ï¼Œå¯¦éš›éƒ¨ç½²æ™‚å°‡é€£æ¥çœŸå¯¦çš„ Kubernetes é›†ç¾¤å’Œ Prometheus ç›£æ§ç³»çµ±ã€‚"""
    
    else:
        assistant_response = f"""æ„Ÿè¬æ‚¨çš„æŸ¥è©¢ï¼šã€Œ{user_message}ã€

ğŸš€ **é€™æ˜¯æ¼”ç¤ºæ¨¡å¼çš„ AI åŠ©æ‰‹å›æ‡‰ï¼**

åœ¨å¯¦éš›ç’°å¢ƒä¸­ï¼Œæˆ‘å¯ä»¥ï¼š
- åŸ·è¡Œ PromQL æŸ¥è©¢åˆ†æé›†ç¾¤æŒ‡æ¨™
- æä¾›å³æ™‚çš„ Kubernetes è³‡æºåˆ†æ
- å”åŠ©æ•…éšœæ’é™¤å’Œæ•ˆèƒ½å„ªåŒ–

**å¯å˜—è©¦çš„æŸ¥è©¢ç¯„ä¾‹ï¼š**
- "é¡¯ç¤ºæ‰€æœ‰ Pod çš„è³‡æºä½¿ç”¨æƒ…æ³"
- "å“ªäº› Pod ä½¿ç”¨æœ€å¤š CPUï¼Ÿ"
- "æœ‰å“ªäº› Pod ç‹€æ…‹ç•°å¸¸ï¼Ÿ"
- "å¹«åŠ©æˆ‘äº†è§£ç³»çµ±åŠŸèƒ½"

è«‹å˜—è©¦å•æˆ‘é—œæ–¼ Kubernetes ç›£æ§çš„å•é¡Œï¼"""

    # Build new history
    new_history = current_history + [
        {"role": "user", "content": user_message},
        {"role": "assistant", "content": assistant_response}
    ]

    return ChatResponse(
        assistant=assistant_response,
        history=new_history
    )